{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2304)\n",
      "(3589, 2304)\n",
      "(3589, 2304)\n",
      "Save data finish!!!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file = 'fer2013.csv'\n",
    "\n",
    "# Creat the list to store the data and label information\n",
    "Training_x = []\n",
    "Training_y = []\n",
    "PublicTest_x = []\n",
    "PublicTest_y = []\n",
    "PrivateTest_x = []\n",
    "PrivateTest_y = []\n",
    "\n",
    "datapath = os.path.join('data','data.h5')\n",
    "if not os.path.exists(os.path.dirname(datapath)):\n",
    "    os.makedirs(os.path.dirname(datapath))\n",
    "\n",
    "with open(file,'r') as csvin:\n",
    "    data=csv.reader(csvin)\n",
    "    for row in data:\n",
    "        if row[-1] == 'Training':\n",
    "            temp_list = []\n",
    "            for pixel in row[1].split( ):\n",
    "                temp_list.append(int(pixel))\n",
    "            I = np.asarray(temp_list)\n",
    "            Training_y.append(int(row[0]))\n",
    "            Training_x.append(I.tolist())\n",
    "\n",
    "        if row[-1] == \"PublicTest\" :\n",
    "            temp_list = []\n",
    "            for pixel in row[1].split( ):\n",
    "                temp_list.append(int(pixel))\n",
    "            I = np.asarray(temp_list)\n",
    "            PublicTest_y.append(int(row[0]))\n",
    "            PublicTest_x.append(I.tolist())\n",
    "\n",
    "        if row[-1] == 'PrivateTest':\n",
    "            temp_list = []\n",
    "            for pixel in row[1].split( ):\n",
    "                temp_list.append(int(pixel))\n",
    "            I = np.asarray(temp_list)\n",
    "\n",
    "            PrivateTest_y.append(int(row[0]))\n",
    "            PrivateTest_x.append(I.tolist())\n",
    "\n",
    "print(np.shape(Training_x))\n",
    "print(np.shape(PublicTest_x))\n",
    "print(np.shape(PrivateTest_x))\n",
    "\n",
    "datafile = h5py.File(datapath, 'w')\n",
    "datafile.create_dataset(\"Training_pixel\", dtype = 'uint8', data=Training_x)\n",
    "datafile.create_dataset(\"Training_label\", dtype = 'int64', data=Training_y)\n",
    "datafile.create_dataset(\"PublicTest_pixel\", dtype = 'uint8', data=PublicTest_x)\n",
    "datafile.create_dataset(\"PublicTest_label\", dtype = 'int64', data=PublicTest_y)\n",
    "datafile.create_dataset(\"PrivateTest_pixel\", dtype = 'uint8', data=PrivateTest_x)\n",
    "datafile.create_dataset(\"PrivateTest_label\", dtype = 'int64', data=PrivateTest_y)\n",
    "datafile.close()\n",
    "\n",
    "print(\"Save data finish!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "dataset_path = 'fer2013.csv'\n",
    "image_size=(48,48)\n",
    " \n",
    "def load_fer2013():\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).values\n",
    "    return faces, emotions\n",
    " \n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    " \n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "input_shape = (48, 48, 1)\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = 'data/'\n",
    "l2_regularization=0.01\n",
    "\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    " \n",
    "# model parameters\n",
    "regularization = l2(l2_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 46, 46, 8)    72          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 46, 46, 8)    32          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 46, 46, 8)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 44, 44, 8)    576         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 44, 44, 8)    32          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 44, 44, 8)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 44, 44, 16)   200         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 44, 44, 16)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 44, 44, 16)   400         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 22, 22, 16)   128         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 22, 22, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 22, 22, 16)   64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 22, 22, 16)   0           max_pooling2d_9[0][0]            \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 22, 22, 32)   656         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 22, 22, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 22, 22, 32)   1312        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 32)   512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 11, 11, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 11, 11, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 11, 11, 32)   0           max_pooling2d_10[0][0]           \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 11, 11, 64)   2336        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 11, 11, 64)   4672        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 6, 6, 64)     2048        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 6, 6, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 6, 6, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 6, 64)     0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 6, 6, 128)    8768        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 6, 6, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 6, 6, 128)    17536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 3, 3, 128)    8192        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 3, 3, 128)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 3, 3, 128)    512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 128)    0           max_pooling2d_12[0][0]           \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 3, 3, 7)      8071        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 7)            0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# base\n",
    "img_input = Input(input_shape)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    " \n",
    "# module 1\n",
    "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 2\n",
    "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 3\n",
    "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 4\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax',name='predictions')(x)\n",
    " \n",
    "model = Model(img_input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "898/897 [==============================] - 537s 598ms/step - loss: 1.5240 - accuracy: 0.4317 - val_loss: 1.5563 - val_accuracy: 0.4147\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55630, saving model to data/_mini_XCEPTION.01.hdf5\n",
      "Epoch 2/15\n",
      "898/897 [==============================] - 342s 381ms/step - loss: 1.4132 - accuracy: 0.4741 - val_loss: 1.5570 - val_accuracy: 0.4518\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.55630\n",
      "Epoch 3/15\n",
      "898/897 [==============================] - 296s 330ms/step - loss: 1.3468 - accuracy: 0.4951 - val_loss: 1.5957 - val_accuracy: 0.4256\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.55630\n",
      "Epoch 4/15\n",
      "898/897 [==============================] - 296s 329ms/step - loss: 1.3025 - accuracy: 0.5124 - val_loss: 1.3026 - val_accuracy: 0.5231\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.55630 to 1.30255, saving model to data/_mini_XCEPTION.04.hdf5\n",
      "Epoch 5/15\n",
      "898/897 [==============================] - 292s 325ms/step - loss: 1.2589 - accuracy: 0.5280 - val_loss: 1.3168 - val_accuracy: 0.5178\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.30255\n",
      "Epoch 6/15\n",
      "898/897 [==============================] - 293s 327ms/step - loss: 1.2331 - accuracy: 0.5404 - val_loss: 1.3265 - val_accuracy: 0.5056\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.30255\n",
      "Epoch 7/15\n",
      "898/897 [==============================] - 298s 331ms/step - loss: 1.2096 - accuracy: 0.5459 - val_loss: 1.2809 - val_accuracy: 0.5337\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.30255 to 1.28093, saving model to data/_mini_XCEPTION.07.hdf5\n",
      "Epoch 8/15\n",
      "898/897 [==============================] - 299s 332ms/step - loss: 1.1920 - accuracy: 0.5518 - val_loss: 1.1670 - val_accuracy: 0.5538\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.28093 to 1.16699, saving model to data/_mini_XCEPTION.08.hdf5\n",
      "Epoch 9/15\n",
      "898/897 [==============================] - 294s 327ms/step - loss: 1.1698 - accuracy: 0.5599 - val_loss: 1.1878 - val_accuracy: 0.5585\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.16699\n",
      "Epoch 10/15\n",
      "898/897 [==============================] - 292s 326ms/step - loss: 1.1542 - accuracy: 0.5682 - val_loss: 1.1668 - val_accuracy: 0.5670\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.16699 to 1.16680, saving model to data/_mini_XCEPTION.10.hdf5\n",
      "Epoch 11/15\n",
      "898/897 [==============================] - 304s 338ms/step - loss: 1.1400 - accuracy: 0.5719 - val_loss: 1.1337 - val_accuracy: 0.5794\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.16680 to 1.13365, saving model to data/_mini_XCEPTION.11.hdf5\n",
      "Epoch 12/15\n",
      "898/897 [==============================] - 294s 328ms/step - loss: 1.1263 - accuracy: 0.5778 - val_loss: 1.2466 - val_accuracy: 0.5467\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.13365\n",
      "Epoch 13/15\n",
      "898/897 [==============================] - 293s 326ms/step - loss: 1.1198 - accuracy: 0.5807 - val_loss: 1.2103 - val_accuracy: 0.5428\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.13365\n",
      "Epoch 14/15\n",
      "898/897 [==============================] - 286s 318ms/step - loss: 1.1090 - accuracy: 0.5863 - val_loss: 1.1396 - val_accuracy: 0.5745\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.13365\n",
      "Epoch 15/15\n",
      "898/897 [==============================] - 295s 329ms/step - loss: 1.1012 - accuracy: 0.5865 - val_loss: 1.1453 - val_accuracy: 0.5697\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.13365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x204fdb1db08>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    " \n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_frontalface_default.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model_path = 'data/_mini_XCEPTION.11.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection = cv2.CascadeClassifier(detection_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier = load_model(emotion_model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting video streaming\n",
    "cv2.namedWindow('your_face')\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-483c5d94cec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCASCADE_SCALE_IMAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"uint8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    frame = camera.read()[1]\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=400)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True,\n",
    "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "        (fX, fY, fW, fH) = faces\n",
    "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n",
    "            # the ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        \n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "\n",
    " \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                # construct the label text\n",
    "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "                w = int(prob * 300)\n",
    "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                (255, 255, 255), 2)\n",
    "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('your_face', frameClone)\n",
    "    cv2.imshow(\"Probabilities\", canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
